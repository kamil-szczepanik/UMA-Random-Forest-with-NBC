{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T09:33:29.231543Z",
     "start_time": "2021-08-23T09:33:29.201274Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..\\\\models')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm.contrib.itertools import product\n",
    "from itertools import product\n",
    "\n",
    "from ID3 import ID3\n",
    "from NBC_Categorical import NBC_Categorical\n",
    "from RandomForestClf import RandomForestClf\n",
    "from datasets import get_airline_dataset, get_exams_dataset, get_ecommerce_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_score(X, y, model, n_splits=5):\n",
    "    kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # split()  method generate indices to split data into training and test set.\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        train_X, train_y = X.loc[train_index,:], y.loc[train_index]\n",
    "        test_X, test_y = X.loc[test_index, :], y.loc[test_index]\n",
    "        model.fit(train_X, train_y)\n",
    "        scores.append(model.score(test_X, test_y))\n",
    "    \n",
    "    score = round(sum(scores)/len(scores), 4)\n",
    "    return score\n",
    "\n",
    "def test_accuracy(X, y, model):\n",
    "    return model.score(X, y)\n",
    "\n",
    "\n",
    "def get_conf_matrix(y_test, y_pred, labels):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan eksperymentów\n",
    "\n",
    "Dla każdego zbioru danych:\n",
    "\n",
    "Budowa lasu losowego z parametrami:\n",
    "- jaki procent liczby atrybutów jest losowany: 25%, 50%, 75%\n",
    "- jaki procent przykładów jest losowany: 25%, 50%, 75%\n",
    "- proporcje liczby ID3 do NBC: 25:75, 50:50, 75:25, 100:0\n",
    "- liczba klasyfikatorow: 64, 96, 128\n",
    "\n",
    "Czyli razem 3\\*3\\*3\\*4\\*3=324 doswiadczeń powtórzonych 25 razy i uśrednionych\n",
    "\n",
    "Dla najlepszego znalezionego modelu rysujemy confusion matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForrest:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def score(self):\n",
    "        return 12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_repetitions = 25\n",
    "dataset_loadDataset_valMethod = [(\"exams\", get_exams_dataset), (\"e-commerce\", get_ecommerce_dataset), (\"airline\", get_airline_dataset)] # [(\"exams\", get_exams_dataset)] \n",
    "model_param_attribute_part = [0.25, 0.5, 0.75]\n",
    "model_param_instances_per_classifier = [0.25, 0.5, 0.75]\n",
    "model_param_id3_to_NBC = [(25, 75), (50, 50), (75, 25), (100, 0)]\n",
    "model_param_num_of_classifiers = [64, 96, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: exams\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54bed8376fd4e45bb11cb10685adbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " outer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79600d065dc1481e93c0079c9430039d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " inner loop:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: e-commerce\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff94da20b32e42be8b987cb1069ea836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " outer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49345c5b5da432d96e52d4b9075afb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " inner loop:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: airline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dda914acd9e40f2ae3d0507adac7b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " outer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f76de8a0fd74eb0a77bd50a4978b24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " inner loop:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_results_df = pd.DataFrame(columns=[\"model\", \"accuracy\", \"dataset\", \"attribute part\", \"instances per classifier\", \"id3 to NBC\", \"num of classifiers\"])\n",
    "\n",
    "# Parameter Loops\n",
    "for dataset_name, load_func in dataset_loadDataset_valMethod:\n",
    "    print(\"DATASET:\", dataset_name)\n",
    "    if dataset_name==\"airline\":\n",
    "        (X_train, y_train), (X_test, y_test) = get_airline_dataset(\"train\"), get_airline_dataset(\"test\")\n",
    "    else:\n",
    "        X, y = load_func()\n",
    "        \n",
    "    params_prod = list(product(model_param_attribute_part, \n",
    "                               model_param_instances_per_classifier, \n",
    "                               model_param_id3_to_NBC, \n",
    "                               model_param_num_of_classifiers))\n",
    "    for m_p_attribute_part,m_p_instances_per_classifier,m_p_id3_to_NBC,m_p_num_of_classifiers in tqdm(params_prod, total=len(params_prod), desc=\"Parameters variations\", position=0):\n",
    "                                    \n",
    "        scores = []\n",
    "        # Experiment repetitions loop\n",
    "        for i in tqdm(range(experiment_repetitions), total=experiment_repetitions, desc=\"Experiment repetitions\", position=1, leave=False) :\n",
    "            # model = RandomForrest()\n",
    "            model = NBC_Categorical()\n",
    "            if dataset_name==\"airline\":\n",
    "                model.fit(X_train, y_train)\n",
    "                score = model.score(X_test, y_test)\n",
    "            else:\n",
    "                score = cross_validation_score(X, y, model)\n",
    "                model_name = f\"model\"\n",
    "\n",
    "            scores.append(score)\n",
    "\n",
    "        final_score = np.mean(scores)\n",
    "        models_results_df.loc[len(models_results_df)] = [model_name, \n",
    "                                                         final_score, \n",
    "                                                         dataset_name, \n",
    "                                                         m_p_attribute_part, \n",
    "                                                         m_p_instances_per_classifier, \n",
    "                                                         m_p_id3_to_NBC, \n",
    "                                                         m_p_num_of_classifiers]\n",
    "        \n",
    "    models_results_df.to_csv(\"result.csv\", index=False)\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.2633333333333333\n",
      "\n",
      "ID3:\n",
      "Accuracy: 0.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_exams_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) \n",
    "\n",
    "print(\"\\nNaive Bayes Classifier:\")\n",
    "nbc_classifier = NBC_Categorical()\n",
    "nbc_classifier.fit(X_train, y_train)\n",
    "nbc_classifier.eval(X_test, y_test)\n",
    "\n",
    "print(\"\\nID3:\")\n",
    "id3_tree = ID3()\n",
    "id3_tree.fit(X_train, y_train)\n",
    "id3_tree.eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID3:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2', '3.5', '2', '3.5', '3.5', '3.5', '3.5', '3.5', '2', '2', '2',\n",
       "       '4', '2', '2', '3', '4', '4', '3.5', '3.5', '2', '3.5', '4.5', '2',\n",
       "       '4', '4', '2', '2', '4', '3', '4.5', '2', '3.5', '2', '3', '3.5',\n",
       "       '3', '4', '4', '3.5', '2', '4', '4', '2', '4', '2', '3', '3',\n",
       "       '3.5', '2', '3.5', '2', '3.5', '4', '3.5', '4.5', '3.5', '2', '2',\n",
       "       '3.5', '4', '4', '2', '2', '2', '3.5', '4', '2', '4.5', '4.5',\n",
       "       '4.5', '3', '4', '4', '4', '4.5', '3.5', '2', '4', '3', '3.5',\n",
       "       '3.5', '4', '4.5', '3.5', '5', '3', '4', '4.5', '2', '4', '3.5',\n",
       "       '4', '3', '3.5', '3.5', '4.5', '4', '5', '2', '2', '3.5', '3.5',\n",
       "       '3', '2', '2', '3.5', '4', '4', '3', '4.5', '2', '2', '3', '4',\n",
       "       '2', '2', '4', '3.5', '3.5', '4', '3.5', '3.5', '3', '3', '3', '2',\n",
       "       '2', '3', '2', '3.5', '3', '3.5', '2', '3.5', '3.5', '3', '2',\n",
       "       '3.5', '3', '4', '2', '3.5', None, '3.5', '3.5', '4', '4', '3.5',\n",
       "       '3.5', '4.5', '4', '2', '3.5', '2', '3', '4', '3.5', '4', '3.5',\n",
       "       '4', '2', '3.5', '3', '3', '4', '4.5', '3.5', '4.5', '4', '2', '3',\n",
       "       '2', '3.5', '3', '3.5', '4', '3', '2', '3.5', '4.5', '3.5', '3.5',\n",
       "       '4.5', '3.5', '4', '4', '4', '4.5', '4', '3.5', '2', '5', '3', '3',\n",
       "       '2', '3', '3', '4', '3', '3', '4', '3.5', '3.5', '4', '3', '3',\n",
       "       '2', '2', '3.5', '3', '4', '3.5', '2', '4', '4', '2', '3.5', '4',\n",
       "       '2', '2', '4', '3.5', '2', '3.5', '4', '3', '4', '3.5', '4', '4',\n",
       "       '2', '2', '4', '4', '3.5', '4', '5', '3.5', '3.5', '4', '2', '3.5',\n",
       "       '3.5', '3', '2', '2', '2', '3.5', '2', '4', '3', '4', '4', '3.5',\n",
       "       '4', '3.5', '3.5', '4', '4', '3.5', '4.5', '3.5', '2', '3', '3.5',\n",
       "       '3.5', '2', '2', '3', '3.5', '4.5', '4', '4', '2', '3.5', '3.5',\n",
       "       '3.5', '2', '2', '4', '4', '2', '2', '3.5', '3.5', '3.5', '4', '4',\n",
       "       '3.5', '3.5', '2', '3.5', '4', '4.5', '2', '3', '3.5', '3.5', '3',\n",
       "       '3'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nID3:\")\n",
    "id3_tree = ID3()\n",
    "id3_tree.fit(X_train, y_train)\n",
    "np.array(id3_tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.13666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13666666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_exams_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) \n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "random_forest = RandomForestClf(n_clf=6)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.eval(X_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.6915151515151515\n",
      "\n",
      "ID3:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\experiments_notebook.ipynb Cell 17\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mID3:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m id3_tree \u001b[39m=\u001b[39m ID3()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m id3_tree\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m id3_tree\u001b[39m.\u001b[39meval(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:114\u001b[0m, in \u001b[0;36mID3.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m    112\u001b[0m X_train[labels] \u001b[39m=\u001b[39m y_train\n\u001b[0;32m    113\u001b[0m df \u001b[39m=\u001b[39m X_train\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_tree(df, labels, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:108\u001b[0m, in \u001b[0;36mID3.create_tree\u001b[1;34m(self, df, labels, root, prev_attribute_val)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m branch \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     attribute_val_df \u001b[39m=\u001b[39m df[df[attribute_name] \u001b[39m==\u001b[39m node]\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_tree(attribute_val_df, labels, next_root, node)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:108\u001b[0m, in \u001b[0;36mID3.create_tree\u001b[1;34m(self, df, labels, root, prev_attribute_val)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m branch \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     attribute_val_df \u001b[39m=\u001b[39m df[df[attribute_name] \u001b[39m==\u001b[39m node]\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_tree(attribute_val_df, labels, next_root, node)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:83\u001b[0m, in \u001b[0;36mID3.create_tree\u001b[1;34m(self, df, labels, root, prev_attribute_val)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m attribute_name, _ \u001b[39m=\u001b[39m ID3\u001b[39m.\u001b[39;49mfind_most_informative_attribute(df, labels)\n\u001b[0;32m     85\u001b[0m \u001b[39mif\u001b[39;00m attribute_name \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m: \u001b[39m# is not a non-devisable examples\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     attribute_node, df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_node(df, attribute_name, labels)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:50\u001b[0m, in \u001b[0;36mID3.find_most_informative_attribute\u001b[1;34m(df, labels)\u001b[0m\n\u001b[0;32m     48\u001b[0m best_info_gain \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m attribute \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mdrop([labels]):\n\u001b[1;32m---> 50\u001b[0m     info_gain \u001b[39m=\u001b[39m ID3\u001b[39m.\u001b[39;49minformation_gain(df, attribute, labels)\n\u001b[0;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m best_info_gain \u001b[39m<\u001b[39m info_gain:\n\u001b[0;32m     52\u001b[0m         best_info_gain \u001b[39m=\u001b[39m info_gain\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\ID3.py:39\u001b[0m, in \u001b[0;36mID3.information_gain\u001b[1;34m(df, attribute, labels)\u001b[0m\n\u001b[0;32m     37\u001b[0m info_gain \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     38\u001b[0m total_rows \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfor\u001b[39;00m attr_val \u001b[39min\u001b[39;00m df[attribute]\u001b[39m.\u001b[39;49munique():\n\u001b[0;32m     40\u001b[0m     attr_val_count \u001b[39m=\u001b[39m df[df[attribute] \u001b[39m==\u001b[39m attr_val]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     41\u001b[0m     prop_attr_val \u001b[39m=\u001b[39m attr_val_count\u001b[39m/\u001b[39mtotal_rows\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:2039\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1981\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[0;32m   1982\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1983\u001b[0m \u001b[39m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2037\u001b[0m \u001b[39m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2038\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2039\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49munique()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:973\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    970\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m    972\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(values, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> 973\u001b[0m     result: ArrayLike \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49munique()\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCSeries):\n\u001b[0;32m    975\u001b[0m         \u001b[39m# GH#31182 Series._values returns EA, unpack for backward-compat\u001b[39;00m\n\u001b[0;32m    976\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mtz\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2219\u001b[0m, in \u001b[0;36mCategorical.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2192\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2193\u001b[0m \u001b[39m    Return the ``Categorical`` which ``categories`` and ``codes`` are\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m \u001b[39m    unique.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[39m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2219\u001b[0m     unique_codes \u001b[39m=\u001b[39m unique1d(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcodes)\n\u001b[0;32m   2220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_backing_data(unique_codes)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\algorithms.py:431\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    428\u001b[0m htable, values \u001b[39m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    430\u001b[0m table \u001b[39m=\u001b[39m htable(\u001b[39mlen\u001b[39m(values))\n\u001b[1;32m--> 431\u001b[0m uniques \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39;49munique(values)\n\u001b[0;32m    432\u001b[0m uniques \u001b[39m=\u001b[39m _reconstruct_data(uniques, original\u001b[39m.\u001b[39mdtype, original)\n\u001b[0;32m    433\u001b[0m \u001b[39mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = get_ecommerce_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) \n",
    "\n",
    "print(\"\\nNaive Bayes Classifier:\")\n",
    "nbc_classifier = NBC_Categorical()\n",
    "nbc_classifier.fit(X_train, y_train)\n",
    "nbc_classifier.eval(X_test, y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) \n",
    "\n",
    "print(\"\\nID3:\")\n",
    "id3_tree = ID3()\n",
    "id3_tree.fit(X_train, y_train)\n",
    "id3_tree.eval(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline passenger satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\experiments_notebook.ipynb Cell 19\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nbc_classifier \u001b[39m=\u001b[39m NBC_Categorical()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m nbc_classifier\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m nbc_classifier\u001b[39m.\u001b[39;49meval(X_test, y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m (X_train, y_train), (X_test, y_test) \u001b[39m=\u001b[39m get_airline_dataset(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m), get_airline_dataset(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/Documents/sem8-mgr/UMA/projekt/uma-randomforest-with-nbc/experiments/experiments_notebook.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mID3:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\NBC_Categorical.py:85\u001b[0m, in \u001b[0;36mNBC_Categorical.eval\u001b[1;34m(self, X_test, y_test)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, X_test, y_test):\n\u001b[1;32m---> 85\u001b[0m     acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore( X_test, y_test)\n\u001b[0;32m     86\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m'\u001b[39m, acc)\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m acc\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\NBC_Categorical.py:78\u001b[0m, in \u001b[0;36mNBC_Categorical.score\u001b[1;34m(self, X_test, y_test)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X_test, y_test):\n\u001b[1;32m---> 78\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     79\u001b[0m     y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_test, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[0;32m     80\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_pred, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\NBC_Categorical.py:74\u001b[0m, in \u001b[0;36mNBC_Categorical.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[1;32m---> 74\u001b[0m     preds_df \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_instance(x), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m preds_df\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:8740\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8729\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8731\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   8732\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   8733\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8738\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   8739\u001b[0m )\n\u001b[1;32m-> 8740\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:688\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    686\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 688\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:812\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 812\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    814\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:828\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    826\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    827\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    829\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    830\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    831\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    832\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\NBC_Categorical.py:74\u001b[0m, in \u001b[0;36mNBC_Categorical.predict.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[1;32m---> 74\u001b[0m     preds_df \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_instance(x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m preds_df\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\Documents\\sem8-mgr\\UMA\\projekt\\uma-randomforest-with-nbc\\experiments\\..\\models\\NBC_Categorical.py:68\u001b[0m, in \u001b[0;36mNBC_Categorical.predict_instance\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m     65\u001b[0m labels_probabilites \u001b[39m=\u001b[39m {}\n\u001b[0;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m label, probab \u001b[39min\u001b[39;00m probabilities\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     67\u001b[0m     \u001b[39m# labels_probabilites[label] = probab/np.sum(list(probabilities.values()))\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     labels_probabilites[label] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(logsumexp(probab) \u001b[39m-\u001b[39m  logsumexp(\u001b[39mlist\u001b[39;49m(probabilities\u001b[39m.\u001b[39;49mvalues()) ))\n\u001b[0;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(labels_probabilites, key\u001b[39m=\u001b[39mlabels_probabilites\u001b[39m.\u001b[39mget)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\special\\_logsumexp.py:99\u001b[0m, in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m     96\u001b[0m         a \u001b[39m=\u001b[39m a \u001b[39m+\u001b[39m \u001b[39m0.\u001b[39m  \u001b[39m# promote to at least float\u001b[39;00m\n\u001b[0;32m     97\u001b[0m         a[b \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m---> 99\u001b[0m a_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mamax(a, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m a_max\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    102\u001b[0m     a_max[\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misfinite(a_max)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2754\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[0;32m   2639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2640\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2641\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2752\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[0;32m   2753\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2754\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2755\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_airline_dataset(\"train\"), get_airline_dataset(\"test\")\n",
    "\n",
    "print(\"\\nNaive Bayes Classifier:\")\n",
    "nbc_classifier = NBC_Categorical()\n",
    "nbc_classifier.fit(X_train, y_train)\n",
    "nbc_classifier.eval(X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = get_airline_dataset(\"train\"), get_airline_dataset(\"test\")\n",
    "\n",
    "print(\"\\nID3:\")\n",
    "id3_tree = ID3()\n",
    "id3_tree.fit(X_train, y_train)\n",
    "id3_tree.eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
